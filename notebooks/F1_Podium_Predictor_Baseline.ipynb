{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b42d23",
   "metadata": {},
   "source": [
    "# F1 Podium Predictor (Kaggle CSVs) — Baseline Notebook\n",
    "\n",
    "This notebook builds a **baseline classifier** to predict whether a driver finishes on the podium (top 3) using historical F1 data from a Kaggle dataset (Ergast mirror).\n",
    "\n",
    "## What you'll do\n",
    "1. (Optional) Download a Kaggle dataset of Formula 1 results directly from this notebook (requires your Kaggle API token).\n",
    "2. Load `races.csv`, `results.csv`, and `qualifying.csv`.\n",
    "3. Normalize column names and merge into a modeling table.\n",
    "4. Create a **podium** label, and train a **Logistic Regression** baseline using only `grid`.\n",
    "5. Evaluate and visualize simple insights.\n",
    "\n",
    "> **Tip**: If you already downloaded CSVs manually, place them under `data/raw/` and skip to **Load CSVs**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e31f6",
   "metadata": {},
   "source": [
    "## 0. Environment setup\n",
    "Run this cell once per environment. If you're in a managed environment without internet, comment out the installs and just ensure the packages are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269e1efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, install dependencies (uncomment as necessary)\n",
    "# %pip install -q pandas scikit-learn matplotlib kaggle python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485db0fa",
   "metadata": {},
   "source": [
    "## 1. (Optional) Kaggle download from notebook\n",
    "You need your Kaggle API token file at `~/.kaggle/kaggle.json`.\n",
    "\n",
    "### Steps (once):\n",
    "1. Go to Kaggle → Account → **Create New API Token**; this downloads `kaggle.json`.\n",
    "2. Move it to `~/.kaggle/kaggle.json` and set permissions `chmod 600 ~/.kaggle/kaggle.json`.\n",
    "3. Set your dataset slug below and run the cell to download to `data/raw/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c36483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Kaggle token at /Users/tsuzumi.sato/.kaggle/kaggle.json\n",
      "Dataset URL: https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020\n",
      "License(s): CC0-1.0\n",
      "Downloading formula-1-world-championship-1950-2020.zip to data/raw\n",
      "\n",
      "Downloaded to data/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.28M/6.28M [00:00<00:00, 3.52GB/s]\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib, sys, subprocess, shutil\n",
    "\n",
    "RAW_DIR = pathlib.Path(\"data/raw\")\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# <-- Update this to the dataset you chose on Kaggle (examples in markdown below) -->\n",
    "KAGGLE_DATASET = \"rohanrao/formula-1-world-championship-1950-2020\"  # e.g., \"rohanrao/formula-1-world-championship-1950-2020\" or similar\n",
    "\n",
    "token_path = pathlib.Path.home()/\".kaggle/kaggle.json\"\n",
    "if KAGGLE_DATASET:\n",
    "    if token_path.exists():\n",
    "        print(\"Found Kaggle token at\", token_path)\n",
    "        # Download using Kaggle CLI via subprocess (works in local envs)\n",
    "        try:\n",
    "            subprocess.run(\n",
    "                [\"kaggle\", \"datasets\", \"download\", \"-d\", KAGGLE_DATASET, \"-p\", str(RAW_DIR), \"--unzip\"],\n",
    "                check=True\n",
    "            )\n",
    "            print(\"Downloaded to\", RAW_DIR)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to download via kaggle CLI:\", e)\n",
    "            print(\"Tip: Ensure Kaggle CLI is installed: `pip install kaggle` and that kaggle is on PATH.\")\n",
    "    else:\n",
    "        print(\"Kaggle token not found at ~/.kaggle/kaggle.json. Skipping download. \"\n",
    "              \"Place CSVs in data/raw/ and continue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95bcf10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tsuzumi.sato/.pyenv/shims/python\n",
      "\u001b[33mWARNING: Package(s) not found: kaggle\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!pip show kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69fea8",
   "metadata": {},
   "source": [
    "**Popular Kaggle F1 datasets (examples):**\n",
    "- `rohanrao/formula-1-world-championship-1950-2020`\n",
    "- `muhammadjunaidshahbaz/f1-races-1950-2024`  (if available)\n",
    "- Any Ergast mirrors containing `races.csv`, `results.csv`, `qualifying.csv`\n",
    "\n",
    "Your files should end up like:\n",
    "```\n",
    "data/raw/races.csv\n",
    "data/raw/results.csv\n",
    "data/raw/qualifying.csv\n",
    "```\n",
    "Column names vary slightly; this notebook normalizes them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b36b94",
   "metadata": {},
   "source": [
    "## 2. Imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc003d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Paths\n",
    "RAW = Path(\"data/raw\")\n",
    "PROCESSED = Path(\"data/processed\")\n",
    "PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273674da",
   "metadata": {},
   "source": [
    "## 3. Load CSVs\n",
    "Load the three main files. If your dataset has different names, adjust the paths below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7829ba5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   raceId  year  round  circuitId                   name        date  \\\n",
       " 0       1  2009      1          1  Australian Grand Prix  2009-03-29   \n",
       " 1       2  2009      2          2   Malaysian Grand Prix  2009-04-05   \n",
       " 2       3  2009      3         17     Chinese Grand Prix  2009-04-19   \n",
       " \n",
       "        time                                                url fp1_date  \\\n",
       " 0  06:00:00  http://en.wikipedia.org/wiki/2009_Australian_G...       \\N   \n",
       " 1  09:00:00  http://en.wikipedia.org/wiki/2009_Malaysian_Gr...       \\N   \n",
       " 2  07:00:00  http://en.wikipedia.org/wiki/2009_Chinese_Gran...       \\N   \n",
       " \n",
       "   fp1_time fp2_date fp2_time fp3_date fp3_time quali_date quali_time  \\\n",
       " 0       \\N       \\N       \\N       \\N       \\N         \\N         \\N   \n",
       " 1       \\N       \\N       \\N       \\N       \\N         \\N         \\N   \n",
       " 2       \\N       \\N       \\N       \\N       \\N         \\N         \\N   \n",
       " \n",
       "   sprint_date sprint_time  \n",
       " 0          \\N          \\N  \n",
       " 1          \\N          \\N  \n",
       " 2          \\N          \\N  ,\n",
       "    resultId  raceId  driverId  constructorId number  grid position  \\\n",
       " 0         1      18         1              1     22     1        1   \n",
       " 1         2      18         2              2      3     5        2   \n",
       " 2         3      18         3              3      7     7        3   \n",
       " \n",
       "   positionText  positionOrder  points  laps         time milliseconds  \\\n",
       " 0            1              1    10.0    58  1:34:50.616      5690616   \n",
       " 1            2              2     8.0    58       +5.478      5696094   \n",
       " 2            3              3     6.0    58       +8.163      5698779   \n",
       " \n",
       "   fastestLap rank fastestLapTime fastestLapSpeed  statusId  \n",
       " 0         39    2       1:27.452         218.300         1  \n",
       " 1         41    3       1:27.739         217.586         1  \n",
       " 2         41    5       1:28.090         216.719         1  ,\n",
       "    qualifyId  raceId  driverId  constructorId  number  position        q1  \\\n",
       " 0          1      18         1              1      22         1  1:26.572   \n",
       " 1          2      18         9              2       4         2  1:26.103   \n",
       " 2          3      18         5              1      23         3  1:25.664   \n",
       " \n",
       "          q2        q3  \n",
       " 0  1:25.187  1:26.714  \n",
       " 1  1:25.315  1:26.869  \n",
       " 2  1:25.452  1:27.079  )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races_path = RAW / \"races.csv\"\n",
    "results_path = RAW / \"results.csv\"\n",
    "qualifying_path = RAW / \"qualifying.csv\"\n",
    "\n",
    "assert races_path.exists(), f\"Missing {races_path}\"\n",
    "assert results_path.exists(), f\"Missing {results_path}\"\n",
    "assert qualifying_path.exists(), f\"Missing {qualifying_path}\"\n",
    "\n",
    "races = pd.read_csv(races_path)\n",
    "results = pd.read_csv(results_path)\n",
    "qualifying = pd.read_csv(qualifying_path)\n",
    "\n",
    "races.head(3), results.head(3), qualifying.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb8b6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results columns:  ['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid', 'position', 'positionText', 'positionOrder', 'points', 'laps', 'time', 'milliseconds', 'fastestLap', 'rank', 'fastestLapTime', 'fastestLapSpeed', 'statusId']\n",
      "Races columns:  ['raceId', 'season', 'round', 'circuitId', 'name', 'date', 'time', 'url', 'fp1_date', 'fp1_time', 'fp2_date', 'fp2_time', 'fp3_date', 'fp3_time', 'quali_date', 'quali_time', 'sprint_date', 'sprint_time']\n"
     ]
    }
   ],
   "source": [
    "print(\"Results columns: \", results.columns.tolist())\n",
    "print(\"Races columns: \", races.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9fe6fa",
   "metadata": {},
   "source": [
    "## 4. Normalize column names\n",
    "Different mirrors use slightly different cases. We coerce common keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7800994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['circuitId',\n",
       "  'date',\n",
       "  'fp1_date',\n",
       "  'fp1_time',\n",
       "  'fp2_date',\n",
       "  'fp2_time',\n",
       "  'fp3_date',\n",
       "  'fp3_time',\n",
       "  'name',\n",
       "  'quali_date',\n",
       "  'quali_time',\n",
       "  'raceId',\n",
       "  'round',\n",
       "  'season',\n",
       "  'sprint_date',\n",
       "  'sprint_time',\n",
       "  'time',\n",
       "  'url'],\n",
       " ['constructorId',\n",
       "  'driverId',\n",
       "  'fastestLap',\n",
       "  'fastestLapSpeed',\n",
       "  'fastestLapTime',\n",
       "  'grid',\n",
       "  'laps',\n",
       "  'milliseconds',\n",
       "  'number',\n",
       "  'points',\n",
       "  'position',\n",
       "  'positionOrder',\n",
       "  'positionText',\n",
       "  'raceId',\n",
       "  'rank',\n",
       "  'resultId',\n",
       "  'statusId',\n",
       "  'time'],\n",
       " ['constructorId',\n",
       "  'driverId',\n",
       "  'number',\n",
       "  'position',\n",
       "  'q1',\n",
       "  'q2',\n",
       "  'q3',\n",
       "  'qualifyId',\n",
       "  'raceId'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _normalize_id_cols(df):\n",
    "    lc = {c.lower(): c for c in df.columns}\n",
    "    # Map lower-case names to canonical\n",
    "    rename_map = {}\n",
    "    if 'year' in lc and 'season' not in df.columns:\n",
    "        rename_map[lc['year']] = 'season'\n",
    "    for k in ['driverid','constructorid','raceid','circuitid']:\n",
    "        if k in lc and k[:-2]+'Id' not in df.columns:\n",
    "            # e.g., 'driverid' -> 'driverId'\n",
    "            rename_map[lc[k]] = k[:-2] + 'Id'\n",
    "    if rename_map:\n",
    "        df = df.rename(columns=rename_map)\n",
    "    return df\n",
    "\n",
    "races = _normalize_id_cols(races)\n",
    "results = _normalize_id_cols(results)\n",
    "qualifying = _normalize_id_cols(qualifying)\n",
    "\n",
    "sorted((races.columns)), sorted((results.columns)), sorted((qualifying.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9099a7ed",
   "metadata": {},
   "source": [
    "## 5. Select essentials & merge\n",
    "We build a modeling table keyed by `raceId` + `driverId`. We join qualifying to results, and also attach race metadata for labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a6351c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26759, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>grid</th>\n",
       "      <th>position</th>\n",
       "      <th>statusId</th>\n",
       "      <th>points</th>\n",
       "      <th>grid_quali</th>\n",
       "      <th>season</th>\n",
       "      <th>round</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>circuitId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Australian Grand Prix</td>\n",
       "      <td>2008-03-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raceId  driverId  constructorId  grid  position  statusId  points  \\\n",
       "0      18         1              1     1       1.0         1    10.0   \n",
       "1      18         2              2     5       2.0         1     8.0   \n",
       "2      18         3              3     7       3.0         1     6.0   \n",
       "3      18         4              4    11       4.0         1     5.0   \n",
       "4      18         5              1     3       5.0         1     4.0   \n",
       "\n",
       "   grid_quali  season  round                   name        date  circuitId  \n",
       "0         1.0    2008      1  Australian Grand Prix  2008-03-16          1  \n",
       "1         5.0    2008      1  Australian Grand Prix  2008-03-16          1  \n",
       "2         7.0    2008      1  Australian Grand Prix  2008-03-16          1  \n",
       "3        12.0    2008      1  Australian Grand Prix  2008-03-16          1  \n",
       "4         3.0    2008      1  Australian Grand Prix  2008-03-16          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select columns\n",
    "results_cols = ['raceId','driverId','constructorId','grid','position','points']\n",
    "if 'statusId' in results.columns:\n",
    "    results_cols.insert(5, 'statusId')\n",
    "\n",
    "r = results[results_cols].copy()\n",
    "\n",
    "q = qualifying[['raceId','driverId','position']].copy()\n",
    "q = q.rename(columns={'position':'grid_quali'})\n",
    "\n",
    "# Safe numeric conversion\n",
    "def to_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "r['grid'] = r['grid'].apply(to_int)\n",
    "r['position'] = r['position'].apply(to_int)\n",
    "\n",
    "df = r.merge(q, on=['raceId','driverId'], how='left')\n",
    "\n",
    "if 'year' in races.columns:\n",
    "    races = races.rename(columns={'year': 'season'})\n",
    "\n",
    "race_meta = races[['raceId','season','round','name','date','circuitId']].copy()\n",
    "df = df.merge(race_meta, on=['raceId'], how='left')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa92f1",
   "metadata": {},
   "source": [
    "## 6. Define target & simple filtering\n",
    "For a baseline, we'll:\n",
    "- Keep only cars classified as **finished** (simplifies the first pass)\n",
    "- Create `podium = 1 if position ≤ 3 else 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c3b8bf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'status'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/f1-race-outcome-predictor/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'status'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m finish_like = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstatus\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m).str.contains(\u001b[33m'\u001b[39m\u001b[33mFinished|\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m+1 Lap|\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m+2 Laps|\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m+3 Laps\u001b[39m\u001b[33m'\u001b[39m, case=\u001b[38;5;28;01mFalse\u001b[39;00m, na=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      2\u001b[39m df_baseline = df[finish_like].copy()\n\u001b[32m      3\u001b[39m df_baseline[\u001b[33m'\u001b[39m\u001b[33mpodium\u001b[39m\u001b[33m'\u001b[39m] = df_baseline[\u001b[33m'\u001b[39m\u001b[33mposition\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m x <= \u001b[32m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/f1-race-outcome-predictor/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/f1-race-outcome-predictor/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'status'"
     ]
    }
   ],
   "source": [
    "# finish_like = df['status'].astype(str).str.contains('Finished|\\\\+1 Lap|\\\\+2 Laps|\\\\+3 Laps', case=False, na=False)\n",
    "# df_baseline = df[finish_like].copy()\n",
    "# df_baseline['podium'] = df_baseline['position'].apply(lambda x: 1 if x is not None and x <= 3 else 0)\n",
    "\n",
    "# print(df_baseline.shape)\n",
    "# df_baseline[['season','round','name','driverId','grid','position','podium']].head(10)\n",
    "\n",
    "df['position'] = pd.to_numeric(df['position'], errors='coerce')\n",
    "\n",
    "if 'status' not in df.columns and 'statusId' in df.columns:\n",
    "    status_path = Path(\"data/raw/status.csv\")\n",
    "    if status_path.exists():\n",
    "        status_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca031708",
   "metadata": {},
   "source": [
    "## 7. Save processed table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e33f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = PROCESSED / \"baseline_dataset.csv\"\n",
    "df_baseline.to_csv(out_path, index=False)\n",
    "out_path, len(df_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0303d91",
   "metadata": {},
   "source": [
    "## 8. Baseline model — Logistic Regression (grid → podium)\n",
    "We split **by season** using `GroupShuffleSplit` so the test set simulates unseen seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ebeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = df_baseline.dropna(subset=['grid']).copy()\n",
    "X = model_df[['grid']].astype(float)\n",
    "y = model_df['podium'].astype(int)\n",
    "groups = model_df['season']\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc9e542",
   "metadata": {},
   "source": [
    "## 9. Quick visual checks\n",
    "We look at **podium rate by grid** (test split only) to understand the monotonic trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb52861",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model_df.iloc[test_idx].copy()\n",
    "test['pred'] = y_pred\n",
    "\n",
    "# Podium rate by grid (actual)\n",
    "rate = test.groupby('grid')['podium'].mean()\n",
    "\n",
    "plt.figure()\n",
    "rate.plot(kind='bar')\n",
    "plt.title('Actual Podium Rate by Grid (Test Split)')\n",
    "plt.xlabel('Grid')\n",
    "plt.ylabel('Podium Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b0297",
   "metadata": {},
   "source": [
    "## 10. Next steps\n",
    "- Add **driver/team form** features (rolling avg points last 3–5 races).\n",
    "- Include **track type** (street vs permanent) and **qualifying gap to pole**.\n",
    "- Try **XGBoost** or **Random Forest** for non-linear interactions.\n",
    "- Calibrate probabilities; add reliability plot.\n",
    "- Build a small Streamlit app using the saved model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
